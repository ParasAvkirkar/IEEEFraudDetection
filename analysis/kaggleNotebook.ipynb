{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qw0gJdZTBf9"
   },
   "source": [
    "# Homework 2 - IEEE Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-80k8srTBf-"
   },
   "source": [
    "For all parts below, answer all parts as shown in the Google document for Homework 2. Be sure to include both code that justifies your answer as well as text to answer the questions. We also ask that code be commented to make it easier to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoVV2qQWTBf-"
   },
   "source": [
    "## Part 1 - Fraudulent vs Non-Fraudulent Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gj20jgTCgvyu"
   },
   "outputs": [],
   "source": [
    "# Taking all imports for processing\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pw4TmO0daKML"
   },
   "outputs": [],
   "source": [
    "# loading train-data in dataframes\n",
    "train_identity_df = pd.read_csv(\"../data/train_identity.csv\")\n",
    "train_transaction_df = pd.read_csv(\"../data/train_transaction.csv\")\n",
    "test_identify_df = pd.read_csv('../data/test_identity.csv')\n",
    "test_transaction_df = pd.read_csv('../data/test_transaction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values_in_card6(input_df, is_test_data):\n",
    "    print(\"==================== Solving missing values for card6 ====================\")\n",
    "    modified_df = input_df.copy(deep=True)\n",
    "    if is_test_data:\n",
    "        nan_indices = modified_df.index[modified_df.card6.isnull()]\n",
    "        test_card6_replacements = random.choices(['credit', 'debit'], [36, 64], k=nan_indices.shape[0])\n",
    "        i = 0\n",
    "        for index in nan_indices:\n",
    "            modified_df.iloc[index, modified_df.columns.get_loc('card6')] = test_card6_replacements[i]\n",
    "            if i % 100 == 0:\n",
    "                print(\"Test data card6 filling, done with \" + str(i) + \" , remaining: \" + str(len(nan_indices) - i))\n",
    "            i += 1\n",
    "    else:\n",
    "        non_fraud_indices = modified_df.index[((modified_df.isFraud == 0 ) & modified_df.card6.isnull())]\n",
    "        fraud_indices = modified_df.index[((modified_df.isFraud == 1) & (modified_df.card6.isnull()))]\n",
    "        print( \"Index count: Fraud -> \"+ str(fraud_indices.shape) + \", Non-Fraud ->\" +  str(non_fraud_indices.shape))\n",
    "\n",
    "        fraud_card6_replacements = random.choices(['credit', 'debit'], [48, 51], k=fraud_indices.shape[0])\n",
    "        non_fraud_card6_replacements = random.choices(['credit', 'debit'], [24, 75], k=non_fraud_indices.shape[0])\n",
    "\n",
    "        i = 0\n",
    "        for index in fraud_indices:\n",
    "            modified_df.iloc[index, modified_df.columns.get_loc('card6')] = fraud_card6_replacements[i]\n",
    "            if i % 100 == 0:\n",
    "                print(\"Fraud card6 filling, done with \" + str(i) + \" , remaining: \" + str(len(fraud_indices) - i))\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        for index in non_fraud_indices:\n",
    "            modified_df.iloc[index, modified_df.columns.get_loc('card6')] = non_fraud_card6_replacements[i]\n",
    "            if i % 100 == 0:\n",
    "                print(\"Non fraud card6 filling, done with \" + str(i) + \" , of: \" + str(len(non_fraud_indices) - i))\n",
    "            i += 1\n",
    "    \n",
    "    print(\"==================== Resolved card6 ====================\")\n",
    "    \n",
    "    return modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values_in_card4(input_df, test_data):\n",
    "    print(\"==================== Solving missing values for card4 ====================\")\n",
    "    \n",
    "    modified_df = input_df.copy(deep=True)\n",
    "    if test_data:\n",
    "        nan_indices = modified_df.index[modified_df.card4.isnull()]\n",
    "        test_card4_replacements = random.choices(['visa', 'mastercard', 'american express', 'discover'], [129, 63, 2, 3], k=nan_indices.shape[0])\n",
    "        i = 0\n",
    "        for index in nan_indices:\n",
    "            modified_df.iloc[index, modified_df.columns.get_loc('card4')] = test_card4_replacements[i]\n",
    "            if i % 100 == 0:\n",
    "                print(\"Test data card4 filling, done with \" + str(i) + \" , remaining: \" + str(len(nan_indices) - i))\n",
    "            i += 1\n",
    "    else:\n",
    "        non_fraud_indices = modified_df.index[((modified_df.isFraud == 0 ) & modified_df.card4.isnull())]\n",
    "        fraud_indices = modified_df.index[((modified_df.isFraud == 1) & (modified_df.card4.isnull()))]\n",
    "        print( \"Index count: Fraud -> \"+ str(fraud_indices.shape) + \", Non-Fraud ->\" +  str(non_fraud_indices.shape))\n",
    "\n",
    "        fraud_card4_replacements = random.choices(['visa', 'mastercard', 'american express', 'discover'], [64, 31, 1, 2], k=fraud_indices.shape[0])\n",
    "        non_fraud_card4_replacements = random.choices(['visa', 'mastercard', 'american express', 'discover'], [65, 32, 1, 1], k=non_fraud_indices.shape[0])\n",
    "\n",
    "        i = 0\n",
    "        for index in fraud_indices:\n",
    "            modified_df.iloc[index, modified_df.columns.get_loc('card4')] = fraud_card4_replacements[i]\n",
    "            if i % 100 == 0:\n",
    "                print(\"Fraud, Filling card4 field, done with \" + str(i) + \" , of: \" + str(len(fraud_indices)))\n",
    "            i += 1\n",
    "\n",
    "        i = 0\n",
    "        for index in non_fraud_indices:\n",
    "            modified_df.iloc[index, modified_df.columns.get_loc('card4')] = non_fraud_card4_replacements[i]\n",
    "            if i % 100 == 0:\n",
    "                print(\"Fraud, Filling card4 field, done with \" + str(i) + \" , of: \" + str(len(non_fraud_indices)))\n",
    "            i += 1\n",
    "    \n",
    "    print(\"==================== Resolved card4 ====================\")\n",
    "    \n",
    "    return modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values_in_addr(input_df):\n",
    "    print(\"==================== Solving missing values for addr1/addr2 ====================\")\n",
    "    \n",
    "    modified_df = input_df.copy(deep=True)\n",
    "    \n",
    "    modified_df['addr1'] = modified_df['addr1'].fillna('special_region')\n",
    "    modified_df['addr2'] = modified_df['addr2'].fillna('special_country')\n",
    "    \n",
    "    print(\"==================== Resolved addr1/addr2 ====================\")\n",
    "    \n",
    "    return modified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(input_df, column_names):\n",
    "    print(\"==================== Dropping some columns ====================\")\n",
    "    return input_df.drop(column_names, axis = 1) # non-inplace drop, the input_df will still have its all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col_name, col_prefix=''):\n",
    "    print(\"==================== Encoding \"+ col_name + \" ====================\")\n",
    "    \n",
    "    if len(col_prefix) > 0:\n",
    "        one_hot_encoding = pd.get_dummies(df[col_name], prefix=col_prefix)\n",
    "    else:\n",
    "        one_hot_encoding = pd.get_dummies(df[col_name])\n",
    "    new_df = df.copy(deep=True)\n",
    "    new_df = new_df.drop(col_name, axis=1)\n",
    "    new_df = new_df.join(one_hot_encoding)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_fields(input_df):\n",
    "    print(\"==================== Encoding categorical columns ====================\")\n",
    "    pre_processing_df = input_df.copy(deep=True)\n",
    "    \n",
    "    pre_processing_df = one_hot_encode(pre_processing_df, 'card4')\n",
    "    pre_processing_df = one_hot_encode(pre_processing_df, 'card6')\n",
    "    pre_processing_df = one_hot_encode(pre_processing_df, 'ProductCD')\n",
    "    pre_processing_df = one_hot_encode(pre_processing_df, 'DeviceType')\n",
    "    pre_processing_df = one_hot_encode(pre_processing_df, 'addr1', col_prefix='addr1_')\n",
    "    pre_processing_df = one_hot_encode(pre_processing_df, 'addr2', col_prefix='addr2_')\n",
    "    \n",
    "    print(\"==================== Done encoding categorical fields ====================\")\n",
    "\n",
    "    return pre_processing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_df(identity_df, transaction_df):\n",
    "    print(\"==================== Pre-Processing begins! ====================\")\n",
    "    \n",
    "    global_df = pd.merge(left=transaction_df, right=identity_df, left_on=[\"TransactionID\"],\n",
    "                                       right_on=\"TransactionID\", how=\"left\")\n",
    "    basic_fields_df = global_df[[\"TransactionID\", \"TransactionDT\", \"TransactionAmt\",\n",
    "                                              \"ProductCD\", \"card4\", \"card6\", \"P_emaildomain\", \"R_emaildomain\", \n",
    "                                              \"addr1\", \"addr2\", \"dist1\", \"dist2\", \"isFraud\", \"DeviceType\", \"DeviceInfo\"]]\n",
    "    modified_df = basic_fields_df.copy(deep=True)\n",
    "    print(\"Pre-Processing initial shape: \" + str(modified_df.shape))\n",
    "    \n",
    "    modified_df = handle_missing_values_in_card6(modified_df, False)\n",
    "    modified_df = handle_missing_values_in_card4(modified_df, False)\n",
    "    modified_df = handle_missing_values_in_addr(modified_df)\n",
    "    \n",
    "    pre_processing_df = drop_columns(modified_df, ['TransactionID', 'dist1', 'dist2', 'DeviceInfo', 'P_emaildomain', 'R_emaildomain'])\n",
    "    pre_processing_df = encode_categorical_fields(pre_processing_df)\n",
    "    \n",
    "    print(\"Pre-Processing final shape: \" + str(pre_processing_df.shape))\n",
    "    print(\"==================== Done Pre-Processing ====================\")\n",
    "    \n",
    "    \n",
    "    return pre_processing_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_dummy_columns(test_df, train_columns ):\n",
    "    missing_cols = set(train_columns) - set(test_df.columns)\n",
    "    for c in missing_cols:\n",
    "        test_df[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citation: http://fastml.com/how-to-use-pd-dot-get-dummies-with-the-test-set/\n",
    "def fix_columns(test_df, train_df):  \n",
    "\n",
    "    add_missing_dummy_columns(test_df, train_df.columns)\n",
    "\n",
    "    # make sure we have all the columns we need\n",
    "    assert(set(train_df.columns) - set( test_df.columns ) == set())\n",
    "\n",
    "    extra_cols = set(test_df.columns) - set(train_df.columns)\n",
    "    if extra_cols:\n",
    "        print(\"extra columns:\", extra_cols)\n",
    "\n",
    "    test_df = test_df[train_df.columns]\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_test_df(identity_df, transaction_df, train_df):\n",
    "    print(\"==================== Pre-Processing begins! ====================\")\n",
    "    \n",
    "    global_df = pd.merge(left=transaction_df, right=identity_df, left_on=[\"TransactionID\"],\n",
    "                                       right_on=\"TransactionID\", how=\"left\")\n",
    "    basic_fields_df = global_df[[\"TransactionID\", \"TransactionDT\", \"TransactionAmt\",\n",
    "                                                  \"ProductCD\", \"card4\", \"card6\", \"P_emaildomain\", \"R_emaildomain\", \n",
    "                                                  \"addr1\", \"addr2\", \"dist1\", \"dist2\", \"DeviceType\", \"DeviceInfo\"]]\n",
    "\n",
    "    modified_df = basic_fields_df.copy(deep=True)\n",
    "    print(\"Pre-Processing initial shape: \" + str(modified_df.shape))\n",
    "    \n",
    "    modified_df = handle_missing_values_in_card6(modified_df, True)\n",
    "    modified_df = handle_missing_values_in_card4(modified_df, True)\n",
    "    modified_df = handle_missing_values_in_addr(modified_df)\n",
    "    \n",
    "    pre_processing_df = drop_columns(modified_df, ['TransactionID', 'dist1', 'dist2', 'DeviceInfo', 'P_emaildomain', 'R_emaildomain'])\n",
    "    pre_processing_df = encode_categorical_fields(pre_processing_df)\n",
    "    pre_processing_df = fix_columns(pre_processing_df, train_df)\n",
    "    \n",
    "    print(\"Pre-Processing final shape: \" + str(pre_processing_df.shape))\n",
    "    print(\"==================== Done Pre-Processing ====================\")\n",
    "    \n",
    "    \n",
    "    return pre_processing_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df):\n",
    "    input_dataset_x = df.drop(['isFraud'], axis=1)\n",
    "    input_dataset_y = df['isFraud']\n",
    "    return train_test_split(input_dataset_x, input_dataset_y, random_state=31) # returns X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_predictions, labels=[1,0]):\n",
    "    mat = confusion_matrix(y_test, y_predictions, labels)\n",
    "    print(\"Confusion Marix: \")\n",
    "    print(str(mat))\n",
    "    sns.heatmap(mat, cmap=\"YlGnBu\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_fraud(X_train, y_train, X_test, y_test, proportion = 1.0):\n",
    "    X = pd.concat([X_train, y_train], axis=1)\n",
    "    not_fraud = X[X.isFraud == 0]\n",
    "    fraud = X[X.isFraud == 1]\n",
    "    len_fraud_samples = int(proportion * not_fraud.shape[0])\n",
    "    print(\"Shape before oversampling fraud dataset: Fraud -> \" + str(fraud.shape) + \", Non-Fraud -> \" + str(not_fraud.shape))\n",
    "    print(\"Oversampling fraud samples -> \" + str(len_fraud_samples))\n",
    "    fraud_oversample = resample(fraud, replace=True, n_samples=len_fraud_samples, random_state=31)\n",
    "    oversampled = pd.concat([not_fraud, fraud_oversample])\n",
    "    print(\"Shape after merging oversampled fraud and non-fraud -> \" + str(oversampled.shape))\n",
    "    return oversampled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_and_split(pre_processed_df):\n",
    "    X_train, X_test, y_train, y_test = split_dataset(pre_processed_df)\n",
    "    oversampled = oversample_fraud(X_train, y_train, X_test, y_test)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(oversampled)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifer(pre_processed_df):\n",
    "    print(\"==================== Training begins! ====================\")\n",
    "    X_train, X_test, y_train, y_test = sample_and_split(pre_processed_df)\n",
    "    \n",
    "    dt_classifier = tree.DecisionTreeClassifier()\n",
    "    dt_classifier = dt_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"==================== Training done! ====================\")\n",
    "    \n",
    "    return dt_classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Pre-Processing begins! ====================\n",
      "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
      "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
      "       ...\n",
      "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
      "       'DeviceType', 'DeviceInfo'],\n",
      "      dtype='object', length=434)\n",
      "Pre-Processing initial shape: (590540, 15)\n",
      "==================== Solving missing values for card6 ====================\n",
      "Index count: Fraud -> (39,), Non-Fraud ->(1532,)\n",
      "Fraud card6 filling, done with 0 , remaining: 39\n",
      "Non fraud card6 filling, done with 0 , of: 1532\n",
      "Non fraud card6 filling, done with 100 , of: 1432\n",
      "Non fraud card6 filling, done with 200 , of: 1332\n",
      "Non fraud card6 filling, done with 300 , of: 1232\n",
      "Non fraud card6 filling, done with 400 , of: 1132\n",
      "Non fraud card6 filling, done with 500 , of: 1032\n",
      "Non fraud card6 filling, done with 600 , of: 932\n",
      "Non fraud card6 filling, done with 700 , of: 832\n",
      "Non fraud card6 filling, done with 800 , of: 732\n",
      "Non fraud card6 filling, done with 900 , of: 632\n",
      "Non fraud card6 filling, done with 1000 , of: 532\n",
      "Non fraud card6 filling, done with 1100 , of: 432\n",
      "Non fraud card6 filling, done with 1200 , of: 332\n",
      "Non fraud card6 filling, done with 1300 , of: 232\n",
      "Non fraud card6 filling, done with 1400 , of: 132\n",
      "Non fraud card6 filling, done with 1500 , of: 32\n",
      "==================== Resolved card6 ====================\n",
      "==================== Solving missing values for card4 ====================\n",
      "Index count: Fraud -> (41,), Non-Fraud ->(1536,)\n",
      "Fraud, Filling card4 field, done with 0 , of: 41\n",
      "Fraud, Filling card4 field, done with 0 , of: 1536\n",
      "Fraud, Filling card4 field, done with 100 , of: 1536\n",
      "Fraud, Filling card4 field, done with 200 , of: 1536\n",
      "Fraud, Filling card4 field, done with 300 , of: 1536\n",
      "Fraud, Filling card4 field, done with 400 , of: 1536\n",
      "Fraud, Filling card4 field, done with 500 , of: 1536\n",
      "Fraud, Filling card4 field, done with 600 , of: 1536\n",
      "Fraud, Filling card4 field, done with 700 , of: 1536\n",
      "Fraud, Filling card4 field, done with 800 , of: 1536\n",
      "Fraud, Filling card4 field, done with 900 , of: 1536\n",
      "Fraud, Filling card4 field, done with 1000 , of: 1536\n",
      "Fraud, Filling card4 field, done with 1100 , of: 1536\n",
      "Fraud, Filling card4 field, done with 1200 , of: 1536\n",
      "Fraud, Filling card4 field, done with 1300 , of: 1536\n",
      "Fraud, Filling card4 field, done with 1400 , of: 1536\n",
      "Fraud, Filling card4 field, done with 1500 , of: 1536\n",
      "==================== Resolved card4 ====================\n",
      "==================== Solving missing values for addr1/addr2 ====================\n",
      "==================== Resolved addr1/addr2 ====================\n",
      "==================== Dropping some columns ====================\n",
      "==================== Encoding categorical columns ====================\n",
      "==================== Encoding card4 ====================\n",
      "==================== Encoding card6 ====================\n",
      "==================== Encoding ProductCD ====================\n",
      "==================== Encoding DeviceType ====================\n",
      "==================== Encoding addr1 ====================\n",
      "==================== Encoding addr2 ====================\n",
      "==================== Done encoding categorical fields ====================\n",
      "Pre-Processing final shape: (590540, 426)\n",
      "==================== Done Pre-Processing ====================\n"
     ]
    }
   ],
   "source": [
    "pre_processed_df = pre_process_df(train_identity_df, train_transaction_df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>american express</th>\n",
       "      <th>discover</th>\n",
       "      <th>mastercard</th>\n",
       "      <th>visa</th>\n",
       "      <th>charge card</th>\n",
       "      <th>credit</th>\n",
       "      <th>debit</th>\n",
       "      <th>...</th>\n",
       "      <th>addr2__92.0</th>\n",
       "      <th>addr2__93.0</th>\n",
       "      <th>addr2__94.0</th>\n",
       "      <th>addr2__96.0</th>\n",
       "      <th>addr2__97.0</th>\n",
       "      <th>addr2__98.0</th>\n",
       "      <th>addr2__100.0</th>\n",
       "      <th>addr2__101.0</th>\n",
       "      <th>addr2__102.0</th>\n",
       "      <th>addr2__special_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionDT  TransactionAmt  isFraud  american express  discover  \\\n",
       "0          86400            68.5        0                 0         1   \n",
       "1          86401            29.0        0                 0         0   \n",
       "2          86469            59.0        0                 0         0   \n",
       "3          86499            50.0        0                 0         0   \n",
       "4          86506            50.0        0                 0         0   \n",
       "\n",
       "   mastercard  visa  charge card  credit  debit  ...  addr2__92.0  \\\n",
       "0           0     0            0       1      0  ...            0   \n",
       "1           1     0            0       1      0  ...            0   \n",
       "2           0     1            0       0      1  ...            0   \n",
       "3           1     0            0       0      1  ...            0   \n",
       "4           1     0            0       1      0  ...            0   \n",
       "\n",
       "   addr2__93.0  addr2__94.0  addr2__96.0  addr2__97.0  addr2__98.0  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   addr2__100.0  addr2__101.0  addr2__102.0  addr2__special_country  \n",
       "0             0             0             0                       0  \n",
       "1             0             0             0                       0  \n",
       "2             0             0             0                       0  \n",
       "3             0             0             0                       0  \n",
       "4             0             0             0                       0  \n",
       "\n",
       "[5 rows x 426 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Training begins! ====================\n",
      "Shape before oversampling fraud dataset: Fraud -> (15568, 426), Non-Fraud -> (427337, 426)\n",
      "Oversampling fraud samples -> 427337\n",
      "Shape after merging oversampled fraud and non-fraud -> (854674, 426)\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== Training begins! ====================\")\n",
    "X_train, X_test, y_train, y_test = sample_and_split(pre_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = tree.DecisionTreeClassifier()\n",
    "dt_classifier = dt_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Marix: \n",
      "[[106544      0]\n",
      " [  2994 104131]]\n",
      "Decision Tree accuracy: 0.985987672521517\n",
      "Precision-Recall-Fscore-Support -> (0.9726670196644087, 1.0, 0.9861441489804796, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predictions = dt_classifier.predict(X_test)\n",
    "accuracy_score = dt_classifier.score(X_test, y_test)\n",
    "confusion_mat = plot_confusion_matrix(y_test, y_predictions)\n",
    "print(\"Decision Tree accuracy: \" + str(accuracy_score))\n",
    "prfs = precision_recall_fscore_support(y_test, y_predictions, average='binary')\n",
    "print(\"Precision-Recall-Fscore-Support -> \" + str(prfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation:\n",
    "1.  https://stackoverflow.com/questions/41335718/keep-same-dummy-variable-in-training-and-testing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Pre-Processing begins! ====================\n",
      "Pre-Processing initial shape: (506691, 14)\n",
      "==================== Solving missing values for card6 ====================\n",
      "Test data card6 filling, done with 0 , remaining: 3007\n",
      "Test data card6 filling, done with 100 , remaining: 2907\n",
      "Test data card6 filling, done with 200 , remaining: 2807\n",
      "Test data card6 filling, done with 300 , remaining: 2707\n",
      "Test data card6 filling, done with 400 , remaining: 2607\n",
      "Test data card6 filling, done with 500 , remaining: 2507\n",
      "Test data card6 filling, done with 600 , remaining: 2407\n",
      "Test data card6 filling, done with 700 , remaining: 2307\n",
      "Test data card6 filling, done with 800 , remaining: 2207\n",
      "Test data card6 filling, done with 900 , remaining: 2107\n",
      "Test data card6 filling, done with 1000 , remaining: 2007\n",
      "Test data card6 filling, done with 1100 , remaining: 1907\n",
      "Test data card6 filling, done with 1200 , remaining: 1807\n",
      "Test data card6 filling, done with 1300 , remaining: 1707\n",
      "Test data card6 filling, done with 1400 , remaining: 1607\n",
      "Test data card6 filling, done with 1500 , remaining: 1507\n",
      "Test data card6 filling, done with 1600 , remaining: 1407\n",
      "Test data card6 filling, done with 1700 , remaining: 1307\n",
      "Test data card6 filling, done with 1800 , remaining: 1207\n",
      "Test data card6 filling, done with 1900 , remaining: 1107\n",
      "Test data card6 filling, done with 2000 , remaining: 1007\n",
      "Test data card6 filling, done with 2100 , remaining: 907\n",
      "Test data card6 filling, done with 2200 , remaining: 807\n",
      "Test data card6 filling, done with 2300 , remaining: 707\n",
      "Test data card6 filling, done with 2400 , remaining: 607\n",
      "Test data card6 filling, done with 2500 , remaining: 507\n",
      "Test data card6 filling, done with 2600 , remaining: 407\n",
      "Test data card6 filling, done with 2700 , remaining: 307\n",
      "Test data card6 filling, done with 2800 , remaining: 207\n",
      "Test data card6 filling, done with 2900 , remaining: 107\n",
      "Test data card6 filling, done with 3000 , remaining: 7\n",
      "==================== Resolved card6 ====================\n",
      "==================== Solving missing values for card4 ====================\n",
      "Test data card4 filling, done with 0 , remaining: 3086\n",
      "Test data card4 filling, done with 100 , remaining: 2986\n",
      "Test data card4 filling, done with 200 , remaining: 2886\n",
      "Test data card4 filling, done with 300 , remaining: 2786\n",
      "Test data card4 filling, done with 400 , remaining: 2686\n",
      "Test data card4 filling, done with 500 , remaining: 2586\n",
      "Test data card4 filling, done with 600 , remaining: 2486\n",
      "Test data card4 filling, done with 700 , remaining: 2386\n",
      "Test data card4 filling, done with 800 , remaining: 2286\n",
      "Test data card4 filling, done with 900 , remaining: 2186\n",
      "Test data card4 filling, done with 1000 , remaining: 2086\n",
      "Test data card4 filling, done with 1100 , remaining: 1986\n",
      "Test data card4 filling, done with 1200 , remaining: 1886\n",
      "Test data card4 filling, done with 1300 , remaining: 1786\n",
      "Test data card4 filling, done with 1400 , remaining: 1686\n",
      "Test data card4 filling, done with 1500 , remaining: 1586\n",
      "Test data card4 filling, done with 1600 , remaining: 1486\n",
      "Test data card4 filling, done with 1700 , remaining: 1386\n",
      "Test data card4 filling, done with 1800 , remaining: 1286\n",
      "Test data card4 filling, done with 1900 , remaining: 1186\n",
      "Test data card4 filling, done with 2000 , remaining: 1086\n",
      "Test data card4 filling, done with 2100 , remaining: 986\n",
      "Test data card4 filling, done with 2200 , remaining: 886\n",
      "Test data card4 filling, done with 2300 , remaining: 786\n",
      "Test data card4 filling, done with 2400 , remaining: 686\n",
      "Test data card4 filling, done with 2500 , remaining: 586\n",
      "Test data card4 filling, done with 2600 , remaining: 486\n",
      "Test data card4 filling, done with 2700 , remaining: 386\n",
      "Test data card4 filling, done with 2800 , remaining: 286\n",
      "Test data card4 filling, done with 2900 , remaining: 186\n",
      "Test data card4 filling, done with 3000 , remaining: 86\n",
      "==================== Resolved card4 ====================\n",
      "==================== Solving missing values for addr1/addr2 ====================\n",
      "==================== Resolved addr1/addr2 ====================\n",
      "==================== Dropping some columns ====================\n",
      "==================== Encoding categorical columns ====================\n",
      "==================== Encoding card4 ====================\n",
      "==================== Encoding card6 ====================\n",
      "==================== Encoding ProductCD ====================\n",
      "==================== Encoding DeviceType ====================\n",
      "==================== Encoding addr1 ====================\n",
      "==================== Encoding addr2 ====================\n",
      "==================== Done encoding categorical fields ====================\n",
      "extra columns: {'addr1__229.0', 'addr1__135.0', 'addr1__271.0', 'addr1__422.0', 'addr1__138.0', 'addr1__116.0', 'addr1__442.0', 'addr1__495.0', 'addr1__320.0', 'addr1__293.0', 'addr2__99.0', 'addr1__364.0', 'addr1__222.0', 'addr1__121.0', 'addr1__538.0', 'addr1__150.0', 'addr2__64.0', 'addr1__108.0', 'addr1__109.0', 'addr1__357.0', 'addr1__407.0', 'addr1__179.0', 'addr1__319.0', 'addr1__424.0', 'addr1__367.0', 'addr1__197.0', 'addr1__415.0', 'addr1__421.0', 'addr1__289.0', 'addr2__67.0', 'addr1__533.0', 'addr2__56.0', 'addr1__344.0', 'addr1__398.0', 'addr1__263.0', 'addr1__173.0', 'addr1__440.0', 'addr1__281.0', 'addr1__188.0', 'addr2__81.0', 'addr1__115.0', 'addr1__118.0', 'addr1__419.0', 'addr1__490.0', 'addr1__186.0', 'addr1__413.0', 'addr1__230.0', 'addr1__461.0', 'addr1__475.0', 'addr1__317.0', 'addr1__394.0', 'addr1__212.0', 'addr1__460.0', 'addr1__354.0', 'addr1__267.0', 'addr1__392.0', 'addr1__273.0', 'addr1__350.0', 'addr1__437.0', 'addr1__207.0', 'addr1__532.0', 'addr1__136.0', 'addr1__473.0', 'addr2__11.0', 'addr2__41.0', 'addr1__192.0', 'addr1__311.0', 'addr1__256.0', 'addr1__240.0', 'addr2__95.0', 'addr1__140.0', 'addr1__149.0', 'addr2__85.0', 'addr1__412.0', 'addr2__53.0', 'addr1__510.0', 'addr1__497.0', 'addr1__246.0', 'addr1__288.0', 'addr2__37.0', 'addr1__336.0', 'addr1__449.0', 'addr1__103.0', 'addr1__524.0', 'addr1__107.0', 'addr1__405.0', 'addr2__91.0', 'addr1__487.0', 'addr1__147.0', 'addr1__169.0', 'addr1__455.0', 'addr1__525.0', 'addr2__45.0', 'addr1__266.0', 'addr1__370.0', 'addr1__165.0', 'addr2__12.0', 'addr1__534.0', 'addr1__539.0', 'addr1__423.0', 'addr1__228.0', 'addr1__176.0', 'addr1__291.0', 'addr2__90.0', 'addr2__42.0', 'addr1__287.0', 'addr1__480.0', 'addr1__537.0', 'addr1__342.0', 'addr1__362.0', 'addr2__80.0', 'addr1__209.0', 'addr1__175.0', 'addr1__447.0', 'addr1__388.0', 'addr1__484.0', 'addr1__363.0', 'addr1__285.0', 'addr1__414.0', 'addr1__378.0', 'addr1__380.0', 'addr2__33.0', 'addr1__383.0', 'addr2__58.0', 'addr1__355.0', 'addr1__334.0', 'addr1__438.0', 'addr1__114.0'}\n",
      "Pre-Processing final shape: (506691, 425)\n",
      "==================== Done Pre-Processing ====================\n"
     ]
    }
   ],
   "source": [
    "test_pre_processed_df = pre_process_test_df(test_identify_df, test_transaction_df, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>american express</th>\n",
       "      <th>discover</th>\n",
       "      <th>mastercard</th>\n",
       "      <th>visa</th>\n",
       "      <th>charge card</th>\n",
       "      <th>credit</th>\n",
       "      <th>debit</th>\n",
       "      <th>debit or credit</th>\n",
       "      <th>...</th>\n",
       "      <th>addr2__92.0</th>\n",
       "      <th>addr2__93.0</th>\n",
       "      <th>addr2__94.0</th>\n",
       "      <th>addr2__96.0</th>\n",
       "      <th>addr2__97.0</th>\n",
       "      <th>addr2__98.0</th>\n",
       "      <th>addr2__100.0</th>\n",
       "      <th>addr2__101.0</th>\n",
       "      <th>addr2__102.0</th>\n",
       "      <th>addr2__special_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18403224</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionDT  TransactionAmt  american express  discover  mastercard  \\\n",
       "0       18403224           31.95                 0         0           0   \n",
       "\n",
       "   visa  charge card  credit  debit  debit or credit  ...  addr2__92.0  \\\n",
       "0     1            0       0      1                0  ...            0   \n",
       "\n",
       "   addr2__93.0  addr2__94.0  addr2__96.0  addr2__97.0  addr2__98.0  \\\n",
       "0            0            0            0            0            0   \n",
       "\n",
       "   addr2__100.0  addr2__101.0  addr2__102.0  addr2__special_country  \n",
       "0             0             0             0                       0  \n",
       "\n",
       "[1 rows x 425 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pre_processed_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>american express</th>\n",
       "      <th>discover</th>\n",
       "      <th>mastercard</th>\n",
       "      <th>visa</th>\n",
       "      <th>charge card</th>\n",
       "      <th>credit</th>\n",
       "      <th>debit</th>\n",
       "      <th>debit or credit</th>\n",
       "      <th>...</th>\n",
       "      <th>addr2__92.0</th>\n",
       "      <th>addr2__93.0</th>\n",
       "      <th>addr2__94.0</th>\n",
       "      <th>addr2__96.0</th>\n",
       "      <th>addr2__97.0</th>\n",
       "      <th>addr2__98.0</th>\n",
       "      <th>addr2__100.0</th>\n",
       "      <th>addr2__101.0</th>\n",
       "      <th>addr2__102.0</th>\n",
       "      <th>addr2__special_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501907</th>\n",
       "      <td>13149046</td>\n",
       "      <td>46.725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TransactionDT  TransactionAmt  american express  discover  mastercard  \\\n",
       "501907       13149046          46.725                 0         0           0   \n",
       "\n",
       "        visa  charge card  credit  debit  debit or credit  ...  addr2__92.0  \\\n",
       "501907     1            0       0      1                0  ...            0   \n",
       "\n",
       "        addr2__93.0  addr2__94.0  addr2__96.0  addr2__97.0  addr2__98.0  \\\n",
       "501907            0            0            0            0            0   \n",
       "\n",
       "        addr2__100.0  addr2__101.0  addr2__102.0  addr2__special_country  \n",
       "501907             0             0             0                       1  \n",
       "\n",
       "[1 rows x 425 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_score = dt_classifier.predict_proba(test_pre_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 425)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pre_processed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 2)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 393)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({\"TransactionID\": test_transaction_df[\"TransactionID\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df[\"isFraud\"] = pd.Series(np.array(predictions_score[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(path_or_buf=\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506691, 393)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CSE519 HW2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
